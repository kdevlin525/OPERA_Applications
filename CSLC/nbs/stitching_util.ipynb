{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import numpy as np\n",
    "import warnings\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "from typing import Optional, Tuple, Union\n",
    "from osgeo import gdal, osr, gdal_array\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import fsspec\n",
    "from pyproj import Proj, CRS\n",
    "import matplotlib.pyplot as plt\n",
    "import shapely.wkt as wkt\n",
    "import rasterio\n",
    "from rasterio.crs import CRS\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio import merge\n",
    "import folium\n",
    "from folium import plugins\n",
    "import rioxarray\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from src.cslc_utils import get_s3path, read_cslc, cslc_info, rasterWrite, custom_merge, colorize, getbasemaps, moving_window_mean\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 's3://opera-pst-rs-pop1/products/CSLC_S1'\n",
    "burst_id = ['T144-308014-IW2', \n",
    "            'T144-308015-IW2']\n",
    "\n",
    "# get list of dates\n",
    "b1paths = (open(f\"{burst_id[0]}.txt\",\"r\").read().split(\"\\n\"))\n",
    "b2paths = (open(f\"{burst_id[1]}.txt\",\"r\").read().split(\"\\n\"))\n",
    "dates = [path[40:48] for path in b1paths]\n",
    "nd = len(dates)\n",
    "\n",
    "# send to dataframe\n",
    "file_df = pd.DataFrame({'Date':dates,f'{burst_id[0]}':b1paths,f'{burst_id[1]}':b2paths})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming: s3://opera-pst-rs-pop1/products/CSLC_S1/OPERA_L2_CSLC-S1A_IW_T144-308014-IW2_VV_20151127T135951Z_v0.1_20230708T230140Z/OPERA_L2_CSLC-S1A_IW_T144-308014-IW2_VV_20151127T135951Z_v0.1_20230708T230140Z.h5\n",
      "Streaming: s3://opera-pst-rs-pop1/products/CSLC_S1/OPERA_L2_CSLC-S1A_IW_T144-308015-IW2_VV_20151127T135954Z_v0.1_20230708T230140Z/OPERA_L2_CSLC-S1A_IW_T144-308015-IW2_VV_20151127T135954Z_v0.1_20230708T230140Z.h5\n",
      "Streaming: s3://opera-pst-rs-pop1/products/CSLC_S1/OPERA_L2_CSLC-S1A_IW_T144-308014-IW2_VV_20151221T135950Z_v0.1_20230708T230145Z/OPERA_L2_CSLC-S1A_IW_T144-308014-IW2_VV_20151221T135950Z_v0.1_20230708T230145Z.h5\n",
      "Streaming: s3://opera-pst-rs-pop1/products/CSLC_S1/OPERA_L2_CSLC-S1A_IW_T144-308015-IW2_VV_20151221T135953Z_v0.1_20230708T230145Z/OPERA_L2_CSLC-S1A_IW_T144-308015-IW2_VV_20151221T135953Z_v0.1_20230708T230145Z.h5\n"
     ]
    }
   ],
   "source": [
    "# Read before and after event dataset \n",
    "before = []; after = []  \n",
    "\n",
    "for id in burst_id: \n",
    "    path_h5 = file_df[f'{id}'][0][:-1]\n",
    "    dat = read_cslc(f'{data_dir}/{path_h5}/{path_h5}.h5')\n",
    "    before.append(dat)\n",
    "\n",
    "for id in burst_id:  \n",
    "    path_h5 = file_df[f'{id}'][1][:-1]\n",
    "    dat = read_cslc(f'{data_dir}/{path_h5}/{path_h5}.h5')\n",
    "    after.append(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_h5 = file_df[f'{burst_id[0]}'][0][:-1]\n",
    "xcoor, ycoor, dx, dy, epsg, bounding_polygon, orbit_direction = cslc_info(f'{data_dir}/{path_h5}/{path_h5}.h5')\n",
    "cslc_poly = wkt.loads(bounding_polygon)\n",
    "bbox = [cslc_poly.bounds[0], cslc_poly.bounds[2], cslc_poly.bounds[1], cslc_poly.bounds[3]]\n",
    "bbox1 = bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_h5 = file_df[f'{burst_id[1]}'][0][:-1]\n",
    "xcoor, ycoor, dx, dy, epsg, bounding_polygon, orbit_direction = cslc_info(f'{data_dir}/{path_h5}/{path_h5}.h5')\n",
    "cslc_poly = wkt.loads(bounding_polygon)\n",
    "bbox = [cslc_poly.bounds[0], cslc_poly.bounds[2], cslc_poly.bounds[1], cslc_poly.bounds[3]]\n",
    "bbox2 = bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import Transformer\n",
    "\n",
    "transformer = Transformer.from_crs(f'EPSG:{epsg}', 'EPSG:4326')\n",
    "lat0, lon0 = transformer.transform(0, 0)\n",
    "dlat, dlon = transformer.transform(dx, dy)\n",
    "dlat = np.abs(dlat - lat0)\n",
    "dlon = np.abs(dlon - lon0)\n",
    "latlon_spacing = [dlat,dlon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.4794979231710386e-05"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.019376366698369e-05"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lalo2xy(lat: np.float32,\n",
    "            lon: np.float32,\n",
    "            data_snwe: list,\n",
    "            latlon_step: list,\n",
    "            rounding_method: Optional[str] = 'floor') \\\n",
    "        -> Tuple[np.int16, np.int16]:\n",
    "    \"\"\"\n",
    "    Georeferenced coordinates to image space coordinates.\n",
    "    GDAL raster starting point is the upper left corner.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lat : float\n",
    "        search latitude\n",
    "    lon : float\n",
    "        search longitude\n",
    "    data_snwe : list\n",
    "        [South, North, West, East] bounds of raster\n",
    "        North (y0) and West(x0) as reference point\n",
    "    latlon_step : list\n",
    "        pixel spacing [latitude_spacing, longitude_spacing]\n",
    "    rounding_method : str\n",
    "        rounding method, default is 'floor' other option is 'around'\n",
    "        Read notes below. TODO. test different rounding routines\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x : int\n",
    "        coordinate in image space (x-axis/columns, direction of width)\n",
    "        from x0 (top up column)\n",
    "    y : int\n",
    "        coordinate in image space (y-axis/rows, direction of length)\n",
    "        from y0 (top left row)\n",
    "    \"\"\"\n",
    "\n",
    "    # np.floor works better with points and raster - Need to check why\n",
    "    # but with two rasters sometimes one pixel is missing or is redundant\n",
    "    if rounding_method == 'floor':\n",
    "        x = int(np.floor((lon - data_snwe[2]) / latlon_step[1] + 0.01))\n",
    "        y = int(np.floor((lat - data_snwe[1]) / latlon_step[0] + 0.01))\n",
    "\n",
    "    # np.around works better with two rasters\n",
    "    # test it out, I think it has something to how numpy floor is\n",
    "    # rounding negative values\n",
    "    # example np.around(-125.2) = -125 np.floor(-125.2) = -126\n",
    "    # np.around(125.6) = 126, np.floor(125.6) = 125\n",
    "    elif rounding_method == 'around':\n",
    "        x = int(np.around((lon - data_snwe[2]) / latlon_step[1] + 0.01))\n",
    "        y = int(np.around((lat - data_snwe[1]) / latlon_step[0] + 0.01))\n",
    "\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((slice(-417, 820, None), slice(0, 177, None)),\n",
       " (slice(0, 1237, None), slice(3702, 3879, None)))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_overlap(bbox1,bbox2,latlon_spacing,latlon_spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract overlap bounds\n",
    "def frame_overlap(snwe1: list,\n",
    "                  snwe2: list,\n",
    "                  latlon_step1: list,\n",
    "                  latlon_step2: list,\n",
    "                  latlon_step: Optional[list] = [-0.000833334, 0.000833334]\n",
    "                  ) -> Tuple[tuple, tuple]:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    Use raster metadata to find overlap between two Images\n",
    "    snwe1 : list\n",
    "        [South, North, West, East] bounds of Image-1\n",
    "    snwe2 : list\n",
    "        [South, North, West, East] bounds of Image-2\n",
    "    latlon_step1 : list\n",
    "        latitude and longitude pixel spacing of Image-1\n",
    "    latlon_step2 : list\n",
    "        latitude and longitude pixel spacing of Image-2\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    subset1 : np.slice\n",
    "        Intersection subset [y1:y2, x1:x2] for the Image-1\n",
    "    subset2 : np.slice\n",
    "        Intersection subset [y1:y2, x1:x2] for the Image-2\n",
    "    \"\"\"\n",
    "\n",
    "    snwe = np.vstack([snwe1, snwe2])\n",
    "    # Find overlap bounds\n",
    "    overlap_snwe = [np.max(snwe[:, 0]), np.min(snwe[:, 1]),\n",
    "                    np.max(snwe[:, 2]), np.min(snwe[:, 3])]\n",
    "\n",
    "    # Georeferenced space to image coordinate space\n",
    "    # Frame-1\n",
    "    x1, y1 = lalo2xy(overlap_snwe[1], overlap_snwe[2], snwe1, latlon_step1)\n",
    "    # Frame-2\n",
    "    x2, y2 = lalo2xy(overlap_snwe[1], overlap_snwe[2], snwe2, latlon_step2)\n",
    "\n",
    "    # Overlap bounds - force overlaps to have same dimensions\n",
    "    # latlon_spacing sometimes diff at 13th decimal\n",
    "    length = int(round((overlap_snwe[0] - overlap_snwe[1]) / latlon_step[0]))\n",
    "    width = int(round((overlap_snwe[3] - overlap_snwe[2]) / latlon_step[1]))\n",
    "\n",
    "    subset1 = np.s_[y1:y1 + length, x1:x1 + width]\n",
    "    subset2 = np.s_[y2:y2 + length, x2:x2 + width]\n",
    "\n",
    "    return subset1, subset2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[nan+nanj, nan+nanj, nan+nanj, ..., nan+nanj, nan+nanj, nan+nanj],\n",
       "        [nan+nanj, nan+nanj, nan+nanj, ..., nan+nanj, nan+nanj, nan+nanj],\n",
       "        [nan+nanj, nan+nanj, nan+nanj, ..., nan+nanj, nan+nanj, nan+nanj],\n",
       "        ...,\n",
       "        [nan+nanj, nan+nanj, nan+nanj, ..., nan+nanj, nan+nanj, nan+nanj],\n",
       "        [nan+nanj, nan+nanj, nan+nanj, ..., nan+nanj, nan+nanj, nan+nanj],\n",
       "        [nan+nanj, nan+nanj, nan+nanj, ..., nan+nanj, nan+nanj, nan+nanj]],\n",
       "       dtype=complex64),\n",
       " array([[nan+nanj, nan+nanj, nan+nanj, ..., nan+nanj, nan+nanj, nan+nanj],\n",
       "        [nan+nanj, nan+nanj, nan+nanj, ..., nan+nanj, nan+nanj, nan+nanj],\n",
       "        [nan+nanj, nan+nanj, nan+nanj, ..., nan+nanj, nan+nanj, nan+nanj],\n",
       "        ...,\n",
       "        [nan+nanj, nan+nanj, nan+nanj, ..., nan+nanj, nan+nanj, nan+nanj],\n",
       "        [nan+nanj, nan+nanj, nan+nanj, ..., nan+nanj, nan+nanj, nan+nanj],\n",
       "        [nan+nanj, nan+nanj, nan+nanj, ..., nan+nanj, nan+nanj, nan+nanj]],\n",
       "       dtype=complex64)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[before[0],before[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (4881,20652) into shape (1325,0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m combine_data_to_single([before[\u001b[39m0\u001b[39;49m],before[\u001b[39m1\u001b[39;49m]],[bbox1,bbox2],[latlon_spacing,latlon_spacing])\n",
      "Cell \u001b[0;32mIn[34], line 60\u001b[0m, in \u001b[0;36mcombine_data_to_single\u001b[0;34m(data_list, snwe_list, latlon_step_list, method, latlon_step)\u001b[0m\n\u001b[1;32m     57\u001b[0m         comb_data[i, \u001b[39m0\u001b[39m:data\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], y:y\u001b[39m+\u001b[39mdata\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],\n\u001b[1;32m     58\u001b[0m                   x: x\u001b[39m+\u001b[39mdata\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m]] \u001b[39m=\u001b[39m data\n\u001b[1;32m     59\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m         comb_data[i, y:y\u001b[39m+\u001b[39;49mdata\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], x: x\u001b[39m+\u001b[39;49mdata\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m]] \u001b[39m=\u001b[39m data\n\u001b[1;32m     62\u001b[0m \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n\u001b[1;32m     63\u001b[0m     warnings\u001b[39m.\u001b[39msimplefilter(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, category\u001b[39m=\u001b[39m\u001b[39mRuntimeWarning\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (4881,20652) into shape (1325,0)"
     ]
    }
   ],
   "source": [
    "combine_data_to_single([before[0],before[1]],[bbox1,bbox2],[latlon_spacing,latlon_spacing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4881, 20652)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(before[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_data_to_single(data_list: list,\n",
    "                           snwe_list: list,\n",
    "                           latlon_step_list: list,\n",
    "                           method: Optional[str] = 'mean',\n",
    "                           latlon_step: Optional[list] =\n",
    "                           [-0.000833334, 0.000833334]) \\\n",
    "        -> Tuple[NDArray, NDArray, list]:\n",
    "    \"\"\"\n",
    "    Merge multiple arrays to one array. Combine them in ndarray, then apply\n",
    "    function along the n_layers axis\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_list : list\n",
    "        list of arrays containing raster values\n",
    "    snwe_list : list\n",
    "        list of arrays containing snwe (extent) values\n",
    "    latlon_step_list : list\n",
    "        list of arrays containing pixel spacing in lat and lon direction\n",
    "        for each dataset\n",
    "    method : str\n",
    "        method to merge overlapping pixes, use mean, min, max etc..\n",
    "        TODO: need to refine this part of code\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    comb_data : ndarray\n",
    "        combined data [n_frames, length, width]\n",
    "    SNWE : array\n",
    "        extent of the combined data\n",
    "    latlon_step : array\n",
    "        pixel spacing in lat, lon of combined data\n",
    "\n",
    "    \"\"\"\n",
    "    # Get the maximum extent of all data\n",
    "    n = len(data_list)\n",
    "    snwe_all = np.squeeze([snwe for snwe in snwe_list])\n",
    "\n",
    "    SNWE = np.array([np.min(snwe_all[:, 0]), np.max(snwe_all[:, 1]),\n",
    "                     np.min(snwe_all[:, 2]), np.max(snwe_all[:, 3])]).T\n",
    "\n",
    "    length = abs(int(np.around((SNWE[1] - SNWE[0]) / latlon_step[0] + 0.01)))\n",
    "    width = abs(int(np.around((SNWE[2] - SNWE[3]) / latlon_step[1] + 0.01)))\n",
    "\n",
    "    # create combined data array\n",
    "    # handle if 3D metadata layer\n",
    "    if len(data_list[0].shape) > 2:\n",
    "        comb_data = np.empty((n, data_list[0].shape[0], length, width),\n",
    "                             dtype=np.float64) * np.nan\n",
    "    else:\n",
    "        comb_data = np.empty((n, length, width), dtype=np.float64) * np.nan\n",
    "    for i, data in enumerate(data_list):\n",
    "        x, y = np.abs(lalo2xy(SNWE[1], SNWE[2], snwe_list[i],\n",
    "                              latlon_step_list[i], 'around'))\n",
    "        # handle if 3D metadata layer\n",
    "        if len(data.shape) > 2:\n",
    "            comb_data[i, 0:data.shape[0], y:y+data.shape[1],\n",
    "                      x: x+data.shape[2]] = data\n",
    "        else:\n",
    "            comb_data[i, y:y+data.shape[0], x: x+data.shape[1]] = data\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "        # combine using numpy\n",
    "        if method == 'mean':\n",
    "            comb_data = np.nanmean(comb_data, axis=0)\n",
    "        elif method == 'median':\n",
    "            comb_data = np.nanmedian(comb_data, axis=0)\n",
    "        elif method == 'min':\n",
    "            comb_data = np.nanmin(comb_data, axis=0)\n",
    "        elif method == 'max':\n",
    "            comb_data = np.nanmax(comb_data, axis=0)\n",
    "\n",
    "    return comb_data, SNWE,  latlon_step\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opera_app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
